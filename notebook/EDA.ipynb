{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Dict, List\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data reading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 747,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1=\"/home/redha/Documents/projects/NLP/datamining project/Soil-Fertility/data/Dataset1.csv\"\n",
    "path2=\"/home/redha/Documents/projects/NLP/datamining project/Soil-Fertility/data/Dataset2.csv\"\n",
    "path3=\"/home/redha/Documents/projects/NLP/datamining project/Soil-Fertility/data/Dataset3.xlsx\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(path1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Manipulation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 885 entries, 0 to 884\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   N          885 non-null    int64  \n",
      " 1   P          885 non-null    object \n",
      " 2   K          885 non-null    int64  \n",
      " 3   pH         885 non-null    float64\n",
      " 4   EC         885 non-null    float64\n",
      " 5   OC         884 non-null    float64\n",
      " 6   S          885 non-null    float64\n",
      " 7   Zn         885 non-null    float64\n",
      " 8   Fe         885 non-null    float64\n",
      " 9   Cu         884 non-null    float64\n",
      " 10  Mn         885 non-null    float64\n",
      " 11  B          885 non-null    float64\n",
      " 12  OM         885 non-null    float64\n",
      " 13  Fertility  885 non-null    int64  \n",
      "dtypes: float64(10), int64(3), object(1)\n",
      "memory usage: 96.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# print description of dataset , number of rows and columns , type of each column , number of null values , number of unique values \n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we see the type of P column is object, we need to convert it to numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P : could not convert string to float: '?'\n"
     ]
    }
   ],
   "source": [
    "# let's check if there is any weird values in the dataset\n",
    "for col in df.columns :\n",
    "    try : \n",
    "        df[col].astype(float)\n",
    "    except Exception as e :\n",
    "        print(f\"{col} : {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 751,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows_with_value(df : pd.DataFrame, value_to_drop : List[str | int | float | None] ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Drops rows in a DataFrame where a specified value is found.\n",
    "\n",
    "    Parameters:\n",
    "    - df: pandas DataFrame\n",
    "    - value_to_drop: the value to drop from the specified column\n",
    "\n",
    "    Returns:\n",
    "    - Modified DataFrame with rows containing the specified value dropped\n",
    "    \"\"\"\n",
    "    none_values = [\n",
    "    \"\",\n",
    "    \" \",\n",
    "    \"nan\",\n",
    "    \"NaN\",\n",
    "    \"Nan\",\n",
    "    \"NAN\",\n",
    "    \"None\",\n",
    "    \"none\",\n",
    "    \"NONE\",\n",
    "    \"null\",\n",
    "    \"Null\",\n",
    "    \"NULL\",\n",
    "    \"?\",\n",
    "    \"NA\",\n",
    "    \"na\",\n",
    "    \"Na\",\n",
    "    \"nA\",\n",
    "    None,\n",
    "    np.nan\n",
    "]\n",
    "    new_df=df.copy()\n",
    "    empty_values = none_values+ value_to_drop\n",
    "    \n",
    "    for col in new_df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(new_df[col]):\n",
    "            # Handle numeric columns, including NaN\n",
    "            new_df = new_df[new_df[col].notna() & ~new_df[col].isin(empty_values)]\n",
    "        else:\n",
    "            # Handle non-numeric columns\n",
    "            new_df = new_df[~new_df[col].astype(str).str.lower().isin(empty_values)]\n",
    "\n",
    "    return new_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 752,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=drop_rows_with_value(df,['?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['P']=df['P'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data contain some null values so we have to deal with them before we can start our analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 754,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['OC'].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 755,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_duplicates(df : pd.DataFrame) -> pd.DataFrame :\n",
    "    \"\"\" drop duplicates rows in the dataset\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): dataframe to drop duplicates from\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe without duplicates\n",
    "    \"\"\"\n",
    "    new_df=df.copy()\n",
    "    dataframe_rows = []\n",
    "\n",
    "    for _, row in new_df.iterrows():\n",
    "        row_tuple = tuple(row)\n",
    "        dataframe_rows.append(row_tuple)\n",
    "\n",
    "    dropped_set = set(dataframe_rows)\n",
    "\n",
    "    unique_rows = [list(row_tuple) for row_tuple in dropped_set]\n",
    "\n",
    "    unique_df = pd.DataFrame(unique_rows, columns=new_df.columns)\n",
    "    return unique_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=drop_duplicates(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 757,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878 entries, 0 to 877\n",
      "Data columns (total 14 columns):\n",
      " #   Column     Non-Null Count  Dtype  \n",
      "---  ------     --------------  -----  \n",
      " 0   N          878 non-null    float64\n",
      " 1   P          878 non-null    float64\n",
      " 2   K          878 non-null    float64\n",
      " 3   pH         878 non-null    float64\n",
      " 4   EC         878 non-null    float64\n",
      " 5   OC         878 non-null    float64\n",
      " 6   S          878 non-null    float64\n",
      " 7   Zn         878 non-null    float64\n",
      " 8   Fe         878 non-null    float64\n",
      " 9   Cu         878 non-null    float64\n",
      " 10  Mn         878 non-null    float64\n",
      " 11  B          878 non-null    float64\n",
      " 12  OM         878 non-null    float64\n",
      " 13  Fertility  878 non-null    float64\n",
      "dtypes: float64(14)\n",
      "memory usage: 96.2 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_central_tendencies(df : pd.DataFrame) -> Dict[str,Dict[str,float]]:\n",
    "    \"\"\"this function calculate the central tendencies : mean , median , mode , min , max of each column in the dataframe\n",
    "    Args:\n",
    "        df (pd.Dataframe): pandas dataframe to calculate the central tendencies\n",
    "\n",
    "    Returns:\n",
    "        Dict: dictionary of the central tendencies of each column\n",
    "    \"\"\"\n",
    "    tendencies={}\n",
    "   \n",
    "    for column in df.columns:\n",
    "        #calculate mean \n",
    "        col_len=len(df[column])\n",
    "        mean=sum(df[column])/col_len\n",
    "\n",
    "        #calculate median\n",
    "        sorted_column=sorted(df[column])\n",
    "        if col_len%2==0:\n",
    "            median1 = sorted_column[col_len//2]\n",
    "            median2 = sorted_column[col_len//2-1]\n",
    "            median=(median1+median2)/2\n",
    "        else:\n",
    "            median=sorted_column[col_len//2]\n",
    "\n",
    "        #calculate mode\n",
    "        counter = Counter(df[column])\n",
    "        mode = counter.most_common(1)[0][0] \n",
    "\n",
    "        #calculate min    \n",
    "        minimum=sorted_column[0]\n",
    "\n",
    "        #calculate max\n",
    "        maximum=sorted_column[-1]\n",
    "\n",
    "        #calculate standard deviation\n",
    "        std=0\n",
    "        for data in df[column]:\n",
    "            std+=((data-mean)**2)\n",
    "        std=std/col_len\n",
    "        std=std**0.5\n",
    "\n",
    "        #add statistics to dictionary\n",
    "        tendencies[column]={'min':minimum,'max':maximum,'mean':mean,'median':median,'mode':mode,'std':std}\n",
    "\n",
    "    return tendencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 759,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': {'max': 2.82,\n",
      "       'mean': 0.5861389521640087,\n",
      "       'median': 0.4,\n",
      "       'min': 0.06,\n",
      "       'mode': 0.34},\n",
      " 'Cu': {'max': 3.02,\n",
      "        'mean': 0.9516970387243736,\n",
      "        'median': 0.93,\n",
      "        'min': 0.09,\n",
      "        'mode': 1.25},\n",
      " 'EC': {'max': 0.95,\n",
      "        'mean': 0.5440774487471528,\n",
      "        'median': 0.55,\n",
      "        'min': 0.1,\n",
      "        'mode': 0.62},\n",
      " 'Fe': {'max': 44.0,\n",
      "        'mean': 4.145763097949893,\n",
      "        'median': 3.565,\n",
      "        'min': 0.21,\n",
      "        'mode': 6.32},\n",
      " 'Fertility': {'max': 2.0,\n",
      "               'mean': 0.5876993166287016,\n",
      "               'median': 1.0,\n",
      "               'min': 0.0,\n",
      "               'mode': 1.0},\n",
      " 'K': {'max': 1560.0,\n",
      "       'mean': 501.04214123006835,\n",
      "       'median': 475.0,\n",
      "       'min': 11.0,\n",
      "       'mode': 444.0},\n",
      " 'Mn': {'max': 31.0,\n",
      "        'mean': 8.688359908883855,\n",
      "        'median': 8.364999999999998,\n",
      "        'min': 0.11,\n",
      "        'mode': 7.54},\n",
      " 'N': {'max': 383.0,\n",
      "       'mean': 246.84282460136674,\n",
      "       'median': 257.0,\n",
      "       'min': 6.0,\n",
      "       'mode': 207.0},\n",
      " 'OC': {'max': 24.0,\n",
      "        'mean': 0.6176651480637805,\n",
      "        'median': 0.59,\n",
      "        'min': 0.1,\n",
      "        'mode': 0.88},\n",
      " 'OM': {'max': 41.28,\n",
      "        'mean': 1.0623840546697043,\n",
      "        'median': 1.0148,\n",
      "        'min': 0.172,\n",
      "        'mode': 1.5136},\n",
      " 'P': {'max': 125.0,\n",
      "       'mean': 14.572437357630967,\n",
      "       'median': 8.1,\n",
      "       'min': 2.9,\n",
      "       'mode': 8.3},\n",
      " 'S': {'max': 31.0,\n",
      "       'mean': 7.525239179954438,\n",
      "       'median': 6.64,\n",
      "       'min': 0.64,\n",
      "       'mode': 4.22},\n",
      " 'Zn': {'max': 42.0,\n",
      "        'mean': 0.4694191343963547,\n",
      "        'median': 0.36,\n",
      "        'min': 0.07,\n",
      "        'mode': 0.28},\n",
      " 'pH': {'max': 11.15,\n",
      "        'mean': 7.510706150341692,\n",
      "        'median': 7.5,\n",
      "        'min': 0.9,\n",
      "        'mode': 7.5}}\n"
     ]
    }
   ],
   "source": [
    "tendencies=calculate_central_tendencies(df)\n",
    "pprint(tendencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_columns = len(df.columns)\n",
    "# plot_per_row = 2\n",
    "# num_rows = num_columns // plot_per_row + (num_columns % plot_per_row > 0)\n",
    "\n",
    "# plt.figure(figsize=(12, num_rows * 4))\n",
    "# for i, col in enumerate(df.columns):\n",
    "#     plt.subplot(num_rows, plot_per_row, i + 1)\n",
    "\n",
    "#     try:\n",
    "#         plt.boxplot(df[col]) \n",
    "#         plt.ylabel(\"Values\")\n",
    "#         plt.title(f'Boxplot for {col}')\n",
    "#     except:\n",
    "#         plt.ylabel(\"Values\")\n",
    "#         plt.title(f'Boxplot for {col}')\n",
    "#         pass\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# num_columns = len(df.columns)\n",
    "# plot_per_row = 2\n",
    "# num_rows = num_columns // plot_per_row + (num_columns % plot_per_row > 0)\n",
    "\n",
    "# plt.figure(figsize=(12, num_rows * 4))\n",
    "\n",
    "# for i, col in enumerate(df.columns):\n",
    "#     plt.subplot(num_rows, plot_per_row, i + 1)\n",
    "\n",
    "#     try:\n",
    "#         plt.hist(df[col], alpha=0.5, bins='auto', label='Histogram')\n",
    "#         plt.ylabel(\"Frequency\")\n",
    "#         plt.xlabel(\"Values\")\n",
    "#         plt.title(f'Histogram for {col}')\n",
    "#         plt.legend()\n",
    "#     except:\n",
    "#         plt.ylabel(\"Frequency\")\n",
    "#         plt.xlabel(\"Values\")\n",
    "#         plt.title(f'Histogram for {col}')\n",
    "#         pass\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 762,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# num_columns = len(df.columns)\n",
    "# plot_per_row = 2\n",
    "# num_rows = num_columns // plot_per_row + (num_columns % plot_per_row > 0)\n",
    "\n",
    "# plt.figure(figsize=(12, num_rows * 4))\n",
    "\n",
    "# for i, col in enumerate(df.columns):\n",
    "#     plt.subplot(num_rows, plot_per_row, i + 1)\n",
    "\n",
    "#     try:\n",
    "#         plt.scatter(range(len(df[col])), df[col], alpha=0.5, label='Scatterplot')\n",
    "#         plt.ylabel(\"Values\")\n",
    "#         plt.xlabel(\"Index\")\n",
    "#         plt.title(f'Scatterplot for {col}')\n",
    "#         plt.legend()\n",
    "#     except:\n",
    "#         plt.ylabel(\"Values\")\n",
    "#         plt.xlabel(\"Index\")\n",
    "#         plt.title(f'Scatterplot for {col}')\n",
    "#         pass\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 763,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quartiles(df : pd.DataFrame, percentiles : list) -> Dict[str,List[float]] :\n",
    "    \"\"\" this function calculate the quartiles of each column in the dataframe\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): the dataframe to calculate the quartiles\n",
    "        percentiles (List): list of the percentiles to calculate\n",
    "\n",
    "    Returns:\n",
    "        Dict[str,Dict[str,float]]: dictionary of the quartiles of each column\n",
    "    \"\"\"\n",
    "    new_df=df.copy()\n",
    "    quartiles_dict = {}\n",
    "\n",
    "    for percentile in percentiles:\n",
    "        if not (0 <= percentile <= 1):\n",
    "            raise ValueError(\"Percentile must be between 0 and 1\")\n",
    "\n",
    "    indexes = [(int(percentile * len(new_df)),percentile) for percentile in percentiles]\n",
    "\n",
    "    for col in new_df.columns:\n",
    "        col_quartiles=[]\n",
    "        sorted_column = sorted(new_df[col])\n",
    "        for index,percentile in indexes :\n",
    "            if percentile == 0 :\n",
    "                tendencies=calculate_central_tendencies(new_df)[col]\n",
    "                col_quartiles.append(tendencies.get('min'))\n",
    "            elif percentile == 1 :\n",
    "                col_quartiles.append(tendencies.get('max'))\n",
    "            else :\n",
    "                col_quartiles.append(sorted_column[index])\n",
    "        quartiles_dict[col] = col_quartiles\n",
    "\n",
    "    return quartiles_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 765,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'B': [0.06, 0.27, 0.4, 0.61, 2.82],\n",
      " 'Cu': [0.09, 0.63, 0.93, 1.25, 3.02],\n",
      " 'EC': [0.1, 0.43, 0.55, 0.64, 0.95],\n",
      " 'Fe': [0.21, 2.06, 3.57, 6.32, 44.0],\n",
      " 'Fertility': [0.0, 0.0, 1.0, 1.0, 2.0],\n",
      " 'K': [11.0, 412.0, 475.0, 581.0, 1560.0],\n",
      " 'Mn': [0.11, 6.23, 8.37, 11.48, 31.0],\n",
      " 'N': [6.0, 201.0, 257.0, 307.0, 383.0],\n",
      " 'OC': [0.1, 0.38, 0.59, 0.78, 24.0],\n",
      " 'OM': [0.172, 0.6536, 1.0148, 1.3416, 41.28],\n",
      " 'P': [2.9, 6.8, 8.1, 10.7, 125.0],\n",
      " 'S': [0.64, 4.7, 6.64, 8.75, 31.0],\n",
      " 'Zn': [0.07, 0.28, 0.36, 0.47, 42.0],\n",
      " 'pH': [0.9, 7.35, 7.5, 7.63, 11.15]}\n"
     ]
    }
   ],
   "source": [
    "quartiles_dict = quartiles(df,[0,0.25,0.5,0.75,1])\n",
    "pprint(quartiles_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(df : pd.DataFrame, show : bool = False) -> pd.DataFrame:\n",
    "    \"\"\" Drops outliers from a DataFrame using the IQR method.\n",
    "\n",
    "    Args:\n",
    "        df (pd.Dataframe): the dataset to drop outliers from\n",
    "    \n",
    "    Returns:\n",
    "        pd.Dataframe: the dataset without outliers\n",
    "    \"\"\"\n",
    "    new_df=df.copy()\n",
    "\n",
    "    quartiles_dict = quartiles(new_df, [0, 0.25, 0.5, 0.75, 1])\n",
    "\n",
    "    for col in new_df.columns:\n",
    "        q1, q3 = quartiles_dict[col][1], quartiles_dict[col][3]\n",
    "        iqr = q3 - q1\n",
    "        lower_bound = q1 - 1.5 * iqr\n",
    "        upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "        if show:\n",
    "            print(f\"Column {col} : lower bound = {lower_bound} , upper bound = {upper_bound}\")\n",
    "            print(f\"Outliers : {new_df[(new_df[col] < lower_bound) | (new_df[col] > upper_bound)][col]}\")\n",
    "\n",
    "        new_df = new_df[(new_df[col] >= lower_bound) & (new_df[col] <= upper_bound)]\n",
    "\n",
    "    return new_df\n",
    "\n",
    "def drop_outliers(df : pd.DataFrame, show : bool = False) -> pd.DataFrame:\n",
    "    \"\"\" drop outliers until data stabilizes\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): the dataframe to drop outliers from\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: the dataframe without outliers\n",
    "    \"\"\"\n",
    "    new_df=df.copy()\n",
    "    while True:\n",
    "        df_without_outliers = find_outliers(new_df,show)\n",
    "        if len(df_without_outliers) == len(new_df):\n",
    "            return df_without_outliers\n",
    "        new_df = df_without_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 767,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=drop_outliers(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 768,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(492, 14)"
      ]
     },
     "execution_count": 768,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# normalization de données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MinMax Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minmax scaler = find the min and max of each column and then apply the formula to normalize the data\n",
    "\n",
    "the formula is : (x - min) / (max - min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 769,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MinMaxTransformer(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" MinMaxTransformer function to normalize the data\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): the dataframe to normalize\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: the normalized dataframe\n",
    "    \"\"\"\n",
    "    new_df=df.copy()\n",
    "    infos=calculate_central_tendencies(new_df)\n",
    "    for col in new_df.columns:\n",
    "        max=infos[col].get('max')\n",
    "        min=infos[col].get('min')\n",
    "        diff=max-min\n",
    "        x_diff=new_df[col]-min\n",
    "        new_val=x_diff/diff\n",
    "        new_df[col]=new_val\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N</th>\n",
       "      <th>P</th>\n",
       "      <th>K</th>\n",
       "      <th>pH</th>\n",
       "      <th>EC</th>\n",
       "      <th>OC</th>\n",
       "      <th>S</th>\n",
       "      <th>Zn</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Cu</th>\n",
       "      <th>Mn</th>\n",
       "      <th>B</th>\n",
       "      <th>OM</th>\n",
       "      <th>Fertility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>370.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>729.0</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.10</td>\n",
       "      <td>5.13</td>\n",
       "      <td>0.51</td>\n",
       "      <td>8.05</td>\n",
       "      <td>0.53</td>\n",
       "      <td>11.25</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>314.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>412.0</td>\n",
       "      <td>7.19</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.07</td>\n",
       "      <td>9.95</td>\n",
       "      <td>0.61</td>\n",
       "      <td>7.86</td>\n",
       "      <td>1.03</td>\n",
       "      <td>5.96</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.8404</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>270.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>612.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.59</td>\n",
       "      <td>5.43</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4.21</td>\n",
       "      <td>0.94</td>\n",
       "      <td>7.32</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.0148</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>195.0</td>\n",
       "      <td>8.1</td>\n",
       "      <td>612.0</td>\n",
       "      <td>7.15</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.10</td>\n",
       "      <td>3.32</td>\n",
       "      <td>0.26</td>\n",
       "      <td>3.47</td>\n",
       "      <td>0.93</td>\n",
       "      <td>11.52</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>270.0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>338.0</td>\n",
       "      <td>7.10</td>\n",
       "      <td>0.42</td>\n",
       "      <td>1.07</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.50</td>\n",
       "      <td>3.02</td>\n",
       "      <td>0.87</td>\n",
       "      <td>9.33</td>\n",
       "      <td>0.36</td>\n",
       "      <td>1.8404</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>207.0</td>\n",
       "      <td>6.8</td>\n",
       "      <td>560.0</td>\n",
       "      <td>8.02</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.17</td>\n",
       "      <td>9.65</td>\n",
       "      <td>0.55</td>\n",
       "      <td>3.54</td>\n",
       "      <td>1.54</td>\n",
       "      <td>14.52</td>\n",
       "      <td>0.61</td>\n",
       "      <td>2.0124</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>326.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>560.0</td>\n",
       "      <td>7.60</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.98</td>\n",
       "      <td>8.75</td>\n",
       "      <td>0.45</td>\n",
       "      <td>6.33</td>\n",
       "      <td>0.91</td>\n",
       "      <td>6.23</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6856</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>320.0</td>\n",
       "      <td>9.4</td>\n",
       "      <td>454.0</td>\n",
       "      <td>7.86</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.10</td>\n",
       "      <td>11.46</td>\n",
       "      <td>0.39</td>\n",
       "      <td>6.14</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.51</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.1720</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>138.0</td>\n",
       "      <td>6.1</td>\n",
       "      <td>348.0</td>\n",
       "      <td>7.40</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.88</td>\n",
       "      <td>4.52</td>\n",
       "      <td>0.28</td>\n",
       "      <td>4.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>13.05</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.5136</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>207.0</td>\n",
       "      <td>7.2</td>\n",
       "      <td>655.0</td>\n",
       "      <td>7.02</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.59</td>\n",
       "      <td>5.43</td>\n",
       "      <td>0.48</td>\n",
       "      <td>5.74</td>\n",
       "      <td>1.25</td>\n",
       "      <td>14.85</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.0148</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>492 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         N    P      K    pH    EC    OC      S    Zn    Fe    Cu     Mn  \\\n",
       "2    370.0  9.4  729.0  7.30  0.59  0.10   5.13  0.51  8.05  0.53  11.25   \n",
       "4    314.0  6.8  412.0  7.19  0.32  1.07   9.95  0.61  7.86  1.03   5.96   \n",
       "6    270.0  7.9  612.0  7.50  0.45  0.59   5.43  0.28  4.21  0.94   7.32   \n",
       "8    195.0  8.1  612.0  7.15  0.64  0.10   3.32  0.26  3.47  0.93  11.52   \n",
       "9    270.0  6.6  338.0  7.10  0.42  1.07   4.52  0.50  3.02  0.87   9.33   \n",
       "..     ...  ...    ...   ...   ...   ...    ...   ...   ...   ...    ...   \n",
       "870  207.0  6.8  560.0  8.02  0.60  1.17   9.65  0.55  3.54  1.54  14.52   \n",
       "872  326.0  9.2  560.0  7.60  0.64  0.98   8.75  0.45  6.33  0.91   6.23   \n",
       "873  320.0  9.4  454.0  7.86  0.61  0.10  11.46  0.39  6.14  1.25   4.51   \n",
       "875  138.0  6.1  348.0  7.40  0.41  0.88   4.52  0.28  4.85  0.85  13.05   \n",
       "877  207.0  7.2  655.0  7.02  0.32  0.59   5.43  0.48  5.74  1.25  14.85   \n",
       "\n",
       "        B      OM  Fertility  \n",
       "2    0.29  0.1720        1.0  \n",
       "4    0.34  1.8404        1.0  \n",
       "6    0.34  1.0148        0.0  \n",
       "8    0.34  0.1720        0.0  \n",
       "9    0.36  1.8404        1.0  \n",
       "..    ...     ...        ...  \n",
       "870  0.61  2.0124        0.0  \n",
       "872  0.29  1.6856        1.0  \n",
       "873  0.42  0.1720        1.0  \n",
       "875  0.29  1.5136        0.0  \n",
       "877  0.53  1.0148        0.0  \n",
       "\n",
       "[492 rows x 14 columns]"
      ]
     },
     "execution_count": 770,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 771,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=MinMaxTransformer(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "z score normalization = find the mean and the standard deviation of each column and then apply the formula to normalize the data\n",
    "\n",
    "formula : (x - mean) / std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ZScoreTransformer(df : pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"this function normalize the data using the zscore method\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): the dataframe to normalize\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: dataframe normalized\n",
    "    \"\"\"\n",
    "\n",
    "    new_df=df.copy()\n",
    "    infos=calculate_central_tendencies(new_df)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
